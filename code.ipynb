{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Advanced Lane Finding with OpenCV\n",
    "\n",
    "---\n",
    "## One-time camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done calibrating !\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from moviepy.editor import VideoFileClip\n",
    "%matplotlib qt\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('./camera_cal/calibration*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "\n",
    "# calibrate camera\n",
    "refimg = cv2.imread('./camera_cal/calibration1.jpg')\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, refimg.shape[0:2], None, None)\n",
    "print(\"Done calibrating !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Define all thresholding functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def abs_sobel_thresh(img, orient='x', thresh=(0,255)):\n",
    "    # Grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    if orient == 'x':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0))\n",
    "    if orient == 'y':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1))\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 255\n",
    "\n",
    "    return binary_output\n",
    "\n",
    "def mag_thresh(img, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    # Grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "\n",
    "    gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    scale_factor = np.max(gradmag)/255 \n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8) \n",
    "\n",
    "    binary_output = np.zeros_like(gradmag)\n",
    "    binary_output[(gradmag >= mag_thresh[0]) & (gradmag <= mag_thresh[1])] = 255\n",
    "\n",
    "    return binary_output\n",
    "\n",
    "def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    # Grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "\n",
    "    absgraddir = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "\n",
    "    binary_output =  np.zeros_like(absgraddir)\n",
    "    binary_output[(absgraddir >= thresh[0]) & (absgraddir <= thresh[1])] = 255\n",
    "\n",
    "    return binary_output\n",
    "\n",
    "def saturation_threshold(img, thresh=(0,255)):\n",
    "    # HLS\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    s_channel = hls[:,:,2]\n",
    "    binary_output =  np.zeros_like(s_channel)\n",
    "    binary_output[(s_channel >= thresh[0]) & (s_channel <= thresh[1])] = 255\n",
    "\n",
    "    return binary_output\n",
    "\n",
    "def value_threshold(img, thresh=(0,255)):\n",
    "    # HSV\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    v_channel = hsv[:,:,2]\n",
    "    binary_output =  np.zeros_like(v_channel)\n",
    "    binary_output[(v_channel >= thresh[0]) & (v_channel <= thresh[1])] = 255\n",
    "\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Apply distortion correction and thresholding on test images. Assess optimal thresholding combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with individual filters !\n"
     ]
    }
   ],
   "source": [
    "# distortion correction\n",
    "\n",
    "images = glob.glob('./test_images/test*.jpg')\n",
    "\n",
    "for i, fname in enumerate(images):\n",
    "\n",
    "    img = cv2.imread(fname)\n",
    "    img_undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    out_name = './test_images/undist_test'+str(i)+'.jpg'\n",
    "    cv2.imwrite(out_name,img_undist)\n",
    "\n",
    "    img_thresh = abs_sobel_thresh(img_undist,orient='x',thresh=(20,255))\n",
    "    out_name = './test_images/sobelx_test'+str(i)+'.jpg'\n",
    "    cv2.imwrite(out_name,img_thresh)\n",
    "\n",
    "    img_thresh = abs_sobel_thresh(img_undist,orient='y',thresh=(20,255))\n",
    "    out_name = './test_images/sobely_test'+str(i)+'.jpg'\n",
    "    cv2.imwrite(out_name,img_thresh)\n",
    "\n",
    "    img_thresh = mag_thresh(img_undist,mag_thresh=(20,255))\n",
    "    out_name = './test_images/mag_test'+str(i)+'.jpg'\n",
    "    cv2.imwrite(out_name,img_thresh)\n",
    "\n",
    "    img_thresh = dir_threshold(img_undist,thresh=(0.3,1.7))\n",
    "    out_name = './test_images/dir_test'+str(i)+'.jpg'\n",
    "    cv2.imwrite(out_name,img_thresh)\n",
    "\n",
    "    img_thresh = saturation_threshold(img_undist,thresh=(100,255))\n",
    "    out_name = './test_images/sat_test'+str(i)+'.jpg'\n",
    "    cv2.imwrite(out_name,img_thresh)\n",
    "\n",
    "    img_thresh = value_threshold(img_undist,thresh=(100,255))\n",
    "    out_name = './test_images/val_test'+str(i)+'.jpg'\n",
    "    cv2.imwrite(out_name,img_thresh)\n",
    "\n",
    "print(\"Done with individual filters !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Final chosen threshold combination after experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done !\n"
     ]
    }
   ],
   "source": [
    "def threshold(img):\n",
    "    # detecting clear lines along x and y does better than magnitude or direction\n",
    "    x_thresh = abs_sobel_thresh(img,orient='x',thresh=(20,255))\n",
    "    y_thresh = abs_sobel_thresh(img,orient='y',thresh=(20,255))\n",
    "    # does a good job detecting full color lines i.e. lanes\n",
    "    s_thresh = saturation_threshold(img,thresh=(100,255))\n",
    "    # does a good job eliminating saturated but dark patches i.e. shadows\n",
    "    v_thresh = value_threshold(img,thresh=(100,255))\n",
    "    final = np.zeros_like(img[:,:,0])\n",
    "    final[((x_thresh==255) & (y_thresh==255)) | ((s_thresh==255) & (v_thresh==255))] = 255\n",
    "    return final\n",
    "\n",
    "for i, fname in enumerate(images):\n",
    "    img = cv2.imread(fname)\n",
    "    img_undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    final = threshold(img_undist)\n",
    "    out_name = './test_images/final'+str(i)+'.jpg'\n",
    "    cv2.imwrite(out_name,final)\n",
    "\n",
    "print(\"Done !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## One-time calculation of Perspective transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warp Done !\n"
     ]
    }
   ],
   "source": [
    "# one-time : doesn't change frame to frame\n",
    "def P_transform(img):\n",
    "    \n",
    "    global P\n",
    "    global Pinv\n",
    "    \n",
    "    h = img.shape[0]\n",
    "    w = img.shape[1]\n",
    "    size = (w,h)\n",
    "\n",
    "    # define trapezoid\n",
    "    top_height = 0.63*h\n",
    "    bottom_height = 0.93*h\n",
    "    top_len = 0.1*w\n",
    "    bottom_len = 0.75*w\n",
    "\n",
    "    top_left = [w/2 - top_len/2, top_height]\n",
    "    top_right = [w/2 + top_len/2, top_height]\n",
    "    bottom_left = [w/2 - bottom_len/2, bottom_height]\n",
    "    bottom_right = [w/2 + bottom_len/2, bottom_height]\n",
    "\n",
    "    src = np.float32([top_left, top_right, bottom_left, bottom_right])\n",
    "\n",
    "    cv2.line(img, (int(top_left[0]), int(top_left[1])), (int(top_right[0]), int(top_right[1])), [0,0,255], 4)\n",
    "    cv2.line(img, (int(top_left[0]), int(top_left[1])), (int(bottom_left[0]), int(bottom_left[1])), [0,0,255], 4)\n",
    "    cv2.line(img, (int(bottom_left[0]), int(bottom_left[1])), (int(bottom_right[0]), int(bottom_right[1])), [0,0,255], 4)\n",
    "    cv2.line(img, (int(bottom_right[0]), int(bottom_right[1])), (int(top_right[0]), int(top_right[1])), [0,0,255], 4)\n",
    "\n",
    "    #plt.imshow(img)\n",
    "\n",
    "    # define target rectangle\n",
    "    side_trim = 0.25*w\n",
    "    top_left = [side_trim, 0]\n",
    "    top_right = [w - side_trim, 0]\n",
    "    bottom_left = [side_trim, h]\n",
    "    bottom_right = [w - side_trim, h]\n",
    "\n",
    "    dst = np.float32([top_left, top_right, bottom_left, bottom_right])\n",
    "\n",
    "    P = cv2.getPerspectiveTransform(src, dst)\n",
    "    Pinv = cv2.getPerspectiveTransform(dst, src)\n",
    "\n",
    "# apply calculated P to new images\n",
    "def perspective(img):\n",
    "    global P\n",
    "    size = (img.shape[1],img.shape[0])\n",
    "    result = cv2.warpPerspective(img, P, size, flags=cv2.INTER_LINEAR)\n",
    "    return result\n",
    "\n",
    "ref_img = cv2.imread('./test_images/final0.jpg')\n",
    "P_transform(ref_img)\n",
    "\n",
    "images = glob.glob('./test_images/final*.jpg')\n",
    "for i, fname in enumerate(images):\n",
    "    ref_img = cv2.imread('./test_images/final'+str(i)+'.jpg')\n",
    "    result = perspective(ref_img)\n",
    "    out_name = './test_images/warped'+str(i)+'.jpg'\n",
    "    cv2.imwrite(out_name,result)\n",
    "    \n",
    "print(\"warp Done !\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Finding centers,  and Line tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define a class to hold state for line detection\n",
    "class Line():\n",
    "    def __init__(self, fw, fh, tol, mppx, mppy, n):\n",
    "        self.window_width = fw\n",
    "        self.window_height = fh\n",
    "        self.tolerance = tol\n",
    "        self.meters_per_pixel_x = mppx\n",
    "        self.meters_per_pixel_y = mppy\n",
    "        self.last_N = n\n",
    "        self.all_centers = []\n",
    "        self.current_avg_centers = []\n",
    "        self.lx = []  # x center points - left\n",
    "        self.rx = []  # x center points - right\n",
    "        self.yvals = [] # discrete y points\n",
    "        self.ploty = [] # continuous y points\n",
    "        self.lpoints = [] # continuous x points - left\n",
    "        self.rpoints = [] # continuous x points - right\n",
    "        \n",
    "    # find centers for left & right lanes - at a given level\n",
    "    # level = 0 for initial centers - closest to car\n",
    "    # subsequent levels are as window moves up\n",
    "    # prev_l = prev_r = 0 for level = 0\n",
    "    def find_centers_level(self, img, level, prev_l, prev_r):\n",
    "        h = img.shape[0]\n",
    "        w = img.shape[1]\n",
    "\n",
    "        window_w = self.window_width\n",
    "        window_h = self.window_height\n",
    "        tolerance = self.tolerance\n",
    "\n",
    "        # slightly different based on first vs. incremental\n",
    "        if (level==0):\n",
    "            # pixels covered by bottom half of image - should concentrate pixles vertically on lane centers\n",
    "            vslice = img[int(0.5*h):,:]\n",
    "            # collapse vertically\n",
    "            vsum = np.sum(vslice, axis=0)\n",
    "            # split in horizontal parts - for level 0, these are the 2 equal halves of the full x range\n",
    "            l_start = 0\n",
    "            l_end = int(w/2)\n",
    "            r_start = int(w/2)\n",
    "            r_end = w\n",
    "        else:\n",
    "            # pixels covered by window height at current level\n",
    "            vslice = img[int(h - window_h*(level+1)):int(h - window_h*level),:]\n",
    "            # collapse vertically\n",
    "            vsum = np.sum(vslice, axis=0)\n",
    "            # split in horizontal parts - for levels > 0, this is the \"tolerance range\" around the last found center\n",
    "            l_start = int(prev_l + window_w/2 - tolerance)\n",
    "            l_end = int(prev_l + window_w/2 + tolerance)\n",
    "            r_start = int(prev_r + window_w/2 - tolerance)\n",
    "            r_end = int(prev_r + window_w/2 + tolerance)\n",
    "\n",
    "        l_start = max(l_start,0)\n",
    "        l_end = min(l_end,w)\n",
    "        r_start = max(r_start,0)\n",
    "        r_end = min(r_end,w)\n",
    "        \n",
    "        # now convolve to find location of maximum concentration of pixels\n",
    "        conv_filter = np.ones(window_w)\n",
    "        \n",
    "        #print(\"convolving for left (%d to %d)\" % (l_start, l_end))\n",
    "        conv_l = np.convolve(conv_filter, vsum[l_start:l_end])\n",
    "        new_l = prev_l + np.argmax(conv_l) - window_w/2\n",
    "        #print(\"convolving for right (%d to %d)\" % (r_start, r_end))\n",
    "        conv_r = np.convolve(conv_filter, vsum[r_start:r_end])\n",
    "        new_r = prev_r + np.argmax(conv_r) - window_w/2\n",
    "        \n",
    "        #print(\"found centers at (%d , %d)\" % (new_l, new_r))\n",
    "\n",
    "        return new_l,new_r\n",
    "\n",
    "    # find centers for all levels\n",
    "    def find_centers_all(self, img):\n",
    "        centers = []        \n",
    "        l = 0\n",
    "        r = int(img.shape[1]/2)\n",
    "        num_levels = int(img.shape[0] / self.window_height)\n",
    "        \n",
    "        for level in range(0,num_levels):\n",
    "            new_l, new_r = self.find_centers_level(img, level, l, r)\n",
    "            #print(\"found centers at (%d , %d)\" % (new_l, new_r))\n",
    "            centers.append((new_l,new_r))\n",
    "            l = new_l\n",
    "            r = new_r\n",
    "\n",
    "        # track all found so far\n",
    "        self.all_centers.append(centers)\n",
    "        \n",
    "        # avg last N - XXX not used since not maintaining state across video frames\n",
    "        final = np.average(self.all_centers[-self.last_N:], axis=0)\n",
    "        self.current_avg_centers = final\n",
    "        #return final\n",
    "    \n",
    "    # fit lane lines to the centers found\n",
    "    def fit_lanes(self, img):\n",
    "        # collect left and right lane x points\n",
    "        lx = []\n",
    "        rx = []\n",
    "        centers = self.current_avg_centers\n",
    "        for i in range(len(centers)):\n",
    "            lx.append(centers[i][0])\n",
    "            rx.append(centers[i][1])\n",
    "\n",
    "        # y points corresponding to the x centers\n",
    "        h = int(img.shape[0])\n",
    "        wh = self.window_height\n",
    "        yvals = np.arange(h-wh/2,0,-wh)\n",
    "\n",
    "        # fit quadratic polynomials\n",
    "        left_lane = np.polyfit(yvals,lx,2)\n",
    "        right_lane = np.polyfit(yvals,rx,2)\n",
    "\n",
    "        # continuous line\n",
    "        ploty = range(0,h)\n",
    "        lpoints = left_lane[0]*ploty*ploty + left_lane[1]*ploty + left_lane[2]\n",
    "        rpoints = right_lane[0]*ploty*ploty + right_lane[1]*ploty + right_lane[2]\n",
    "        \n",
    "        # save up everything with the instance\n",
    "        self.lx = lx\n",
    "        self.rx = rx\n",
    "        self.yvals = yvals\n",
    "        self.ploty = ploty\n",
    "        self.lpoints = lpoints\n",
    "        self.rpoints = rpoints\n",
    "    \n",
    "    def pipeline(self,img):\n",
    "    \n",
    "        global mtx\n",
    "        global dist\n",
    "    \n",
    "        undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    \n",
    "        binary = np.zeros_like(i)\n",
    "        thresh = threshold(undist)\n",
    "    \n",
    "        warp = perspective(thresh)\n",
    "    \n",
    "        self.find_centers_all(warp)\n",
    "        self.fit_lanes(warp)\n",
    "\n",
    "        res = self.draw_on_road(warp, undist)\n",
    "    \n",
    "        radius_l, radius_r, shift = self.curvature(warp)\n",
    "        #print(\"(%f %f %f)\" % (radius_l, radius_r, shift))\n",
    "\n",
    "        final = annotate(res, radius_l, radius_r, shift)\n",
    "    \n",
    "        return final\n",
    "    \n",
    "    def draw_on_road(self, img, undist):\n",
    "\n",
    "        global Pinv\n",
    "    \n",
    "        lpoints = self.lpoints\n",
    "        rpoints = self.rpoints\n",
    "        ploty = self.ploty\n",
    "    \n",
    "        # Create an image to draw the lines on\n",
    "        warp_zero = np.zeros_like(img).astype(np.uint8)\n",
    "        color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "        # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "        pts_left = np.array([np.transpose(np.vstack([lpoints, ploty]))])\n",
    "        pts_right = np.array([np.flipud(np.transpose(np.vstack([rpoints, ploty])))])\n",
    "        pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "        # Draw the lane onto the warped blank image\n",
    "        cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "        # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "        newwarp = cv2.warpPerspective(color_warp, Pinv, (img.shape[1], img.shape[0])) \n",
    "        # Combine the result with the original image\n",
    "        result = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)\n",
    "        return result\n",
    "    \n",
    "    def curvature(self, img):\n",
    "        meters_per_pixel_x = self.meters_per_pixel_x\n",
    "        meters_per_pixel_y = self.meters_per_pixel_y\n",
    "        lpoints = self.lpoints\n",
    "        rpoints = self.rpoints\n",
    "        ploty = self.ploty\n",
    "\n",
    "        yvals = self.yvals\n",
    "        lx = instance.lx\n",
    "        rx = instance.rx\n",
    "    \n",
    "        w = int(img.shape[1])\n",
    "\n",
    "        calc_center = (lpoints[-1]+rpoints[-1])/2\n",
    "        shift = calc_center - w/2\n",
    "        real_shift = shift * meters_per_pixel_x\n",
    "\n",
    "        real_left_lane = np.polyfit(np.array(yvals,np.float32)*meters_per_pixel_y, np.array(lx,np.float32)*meters_per_pixel_x, 2)\n",
    "        real_radius_l = ((1+2*real_left_lane[0]*ploty[-1]*meters_per_pixel_y + real_left_lane[1])**2)**1.5 / np.absolute(2*real_left_lane[0])\n",
    "\n",
    "        real_right_lane = np.polyfit(np.array(yvals,np.float32)*meters_per_pixel_y, np.array(rx,np.float32)*meters_per_pixel_x, 2)\n",
    "        real_radius_r = ((1+2*real_right_lane[0]*ploty[-1]*meters_per_pixel_y + real_right_lane[1])**2)**1.5 / np.absolute(2*real_right_lane[0])\n",
    "    \n",
    "        return real_radius_l, real_radius_r, real_shift\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Run on test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find Centers test done !\n"
     ]
    }
   ],
   "source": [
    "images = glob.glob('./test_images/warped*.jpg')\n",
    "\n",
    "for i, fname in enumerate(images):\n",
    "    ref_img = cv2.imread(fname)\n",
    "    \n",
    "    instance = Line(fw = 25, fh = 80, tol = 25, mppx=3.7/700, mppy=30/720, n=15)\n",
    "    img = ref_img[:,:,0]\n",
    "    instance.find_centers_all(img)\n",
    "    centers = instance.current_avg_centers\n",
    "\n",
    "    h = int(img.shape[0])\n",
    "    for j in range(len(centers)):\n",
    "        l = centers[j][0]\n",
    "        r = centers[j][1]\n",
    "        leftx = int(l - 25)\n",
    "        rightx = int(l + 25)\n",
    "        cv2.line(ref_img, (leftx,h), (rightx,h), [0,0,255], 10)\n",
    "        cv2.line(ref_img, (rightx,h), (rightx,h-80), [0,0,255], 10)\n",
    "        cv2.line(ref_img, (rightx,h-80), (leftx,h-80), [0,0,255], 10)\n",
    "        cv2.line(ref_img, (leftx,h-80), (leftx,h), [0,0,255], 10)\n",
    "\n",
    "        leftx = int(r - 25)\n",
    "        rightx = int(r + 25)\n",
    "        cv2.line(ref_img, (leftx,h), (rightx,h), [0,0,255], 10)\n",
    "        cv2.line(ref_img, (rightx,h), (rightx,h-80), [0,0,255], 10)\n",
    "        cv2.line(ref_img, (rightx,h-80), (leftx,h-80), [0,0,255], 10)\n",
    "        cv2.line(ref_img, (leftx,h-80), (leftx,h), [0,0,255], 10)\n",
    "\n",
    "        h = h-80\n",
    "\n",
    "    out_name = './test_images/centers'+str(i)+'.jpg'\n",
    "    cv2.imwrite(out_name,ref_img)\n",
    "\n",
    "print(\"Find Centers test done !\")\n",
    "#plt.imshow(ref_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Draw on road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def draw_on_road_test(img, undist, instance):\n",
    "\n",
    "    global Pinv\n",
    "    \n",
    "    lpoints = instance.lpoints\n",
    "    rpoints = instance.rpoints\n",
    "    ploty = instance.ploty\n",
    "    \n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(img).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([lpoints, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([rpoints, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Pinv, (img.shape[1], img.shape[0])) \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Run on test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Draw on road test done !\n"
     ]
    }
   ],
   "source": [
    "images = glob.glob('./test_images/warped*.jpg')\n",
    "\n",
    "for i, fname in enumerate(images):\n",
    "    instance = Line(fw = 25, fh = 80, tol = 25, mppx=3.7/700, mppy=30/720, n=15)\n",
    "    ref_img = cv2.imread(fname)\n",
    "    undist = cv2.imread('./test_images/undist_test'+str(i)+'.jpg')\n",
    "\n",
    "    img = ref_img[:,:,0]\n",
    "\n",
    "    instance.find_centers_all(img)\n",
    "    instance.fit_lanes(img)\n",
    "\n",
    "    result = draw_on_road_test(img, undist, instance)\n",
    "\n",
    "    out_name = './test_images/onroad'+str(i)+'.jpg'\n",
    "    cv2.imwrite(out_name,result)\n",
    "\n",
    "print(\"Draw on road test done !\")\n",
    "#plt.imshow(ref_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Find curvature and offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def curvature_test(img, instance):\n",
    "    meters_per_pixel_x = instance.meters_per_pixel_x\n",
    "    meters_per_pixel_y = instance.meters_per_pixel_y\n",
    "    lpoints = instance.lpoints\n",
    "    rpoints = instance.rpoints\n",
    "    ploty = instance.ploty\n",
    "\n",
    "    yvals = instance.yvals\n",
    "    lx = instance.lx\n",
    "    rx = instance.rx\n",
    "    \n",
    "    w = int(img.shape[1])\n",
    "\n",
    "    calc_center = (lpoints[-1]+rpoints[-1])/2\n",
    "    shift = calc_center - w/2\n",
    "    real_shift = shift * meters_per_pixel_x\n",
    "\n",
    "    real_left_lane = np.polyfit(np.array(yvals,np.float32)*meters_per_pixel_y, np.array(lx,np.float32)*meters_per_pixel_x, 2)\n",
    "    real_radius_l = ((1+2*real_left_lane[0]*ploty[-1]*meters_per_pixel_y + real_left_lane[1])**2)**1.5 / np.absolute(2*real_left_lane[0])\n",
    "\n",
    "    real_right_lane = np.polyfit(np.array(yvals,np.float32)*meters_per_pixel_y, np.array(rx,np.float32)*meters_per_pixel_x, 2)\n",
    "    real_radius_r = ((1+2*real_right_lane[0]*ploty[-1]*meters_per_pixel_y + real_right_lane[1])**2)**1.5 / np.absolute(2*real_right_lane[0])\n",
    "    \n",
    "    return real_radius_l, real_radius_r, real_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def annotate(img, radius_l, radius_r, shift):\n",
    "    cv2.putText(img,\"Radius left= \"+str(round(radius_l,2)) , (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "    cv2.putText(img,\"Radius right= \"+str(round(radius_r,2)) , (50,100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "    cv2.putText(img,\"Shift = \"+str(round(shift,2)) , (50,150), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Run on test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curvature test done !\n"
     ]
    }
   ],
   "source": [
    "images = glob.glob('./test_images/warped*.jpg')\n",
    "\n",
    "for i, fname in enumerate(images):\n",
    "    instance = Line(fw = 25, fh = 80, tol = 25, mppx=3.7/700, mppy=30/720, n=15)\n",
    "    ref_img = cv2.imread(fname)\n",
    "    undist = cv2.imread('./test_images/undist_test'+str(i)+'.jpg')\n",
    "\n",
    "    img = ref_img[:,:,0]\n",
    "\n",
    "    instance.find_centers_all(img)\n",
    "    instance.fit_lanes(img)\n",
    "\n",
    "    result = draw_on_road_test(img, undist, instance)\n",
    "\n",
    "    radius_l, radius_r, shift = curvature_test(img,instance)\n",
    "\n",
    "    result = annotate(result, radius_l, radius_r, shift)\n",
    "\n",
    "    out_name = './test_images/curvature'+str(i)+'.jpg'\n",
    "    cv2.imwrite(out_name,result)\n",
    "\n",
    "print(\"Curvature test done !\")\n",
    "#plt.imshow(ref_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Complete pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def pipeline_test(img):\n",
    "    \n",
    "    global mtx\n",
    "    global dist\n",
    "    \n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    \n",
    "    binary = np.zeros_like(i)\n",
    "    thresh = threshold(undist)\n",
    "    \n",
    "    warp = perspective(thresh)\n",
    "    \n",
    "    instance = Line(fw = 25, fh = 80, tol = 25, mppx=3.7/700, mppy=30/720, n=15)    \n",
    "    instance.find_centers_all(warp)\n",
    "    instance.fit_lanes(warp)\n",
    "\n",
    "    res = draw_on_road_test(warp, undist, instance)\n",
    "    \n",
    "    radius_l, radius_r, shift = curvature_test(warp,instance)\n",
    "    #print(\"(%f %f %f)\" % (radius_l, radius_r, shift))\n",
    "\n",
    "    final = annotate(res, radius_l, radius_r, shift)\n",
    "    \n",
    "    return final\n",
    "\n",
    "# Test\n",
    "#img = cv2.imread('./test_images/test4.jpg')\n",
    "#final = pipeline(img)\n",
    "#plt.imshow(final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Process video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video output_video.mp4\n",
      "[MoviePy] Writing video output_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [03:31<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: output_video.mp4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "instance = Line(fw = 25, fh = 80, tol = 25, mppx=3.7/700, mppy=30/720, n=15)\n",
    "clip = VideoFileClip('project_video.mp4')\n",
    "outclip = clip.fl_image(lambda x: instance.pipeline(x))\n",
    "outclip.write_videofile('output_video.mp4',audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
